#  Wafer Map Defect Classification with CNN (WM-811k Case Study)
# üìå Project Overview

This project explores the use of Convolutional Neural Networks (CNNs) for semiconductor wafer defect pattern classification using the WM-811k dataset.

Defect pattern recognition is critical in semiconductor manufacturing for improving yield analysis and fault detection. By leveraging deep learning, we aim to automatically classify wafer maps into multiple defect categories, reducing reliance on manual inspection.

## üìñ Repository Contents (CLICK the link HERE to access the file)
- [`README.md`](https://github.com/cchiayik/Wafer-Map-Defect-Classification-with-CNN-WM-811k-Case-Study-/blob/main/README.md) ‚Üí Project summary (this file)  
- [`pseudocode.md`](https://github.com/cchiayik/Wafer-Map-Defect-Classification-with-CNN-WM-811k-Case-Study-/blob/main/pseudocode.md) ‚Üí Step-by-step workflow without exposing full code  
- [`output.md`](https://github.com/cchiayik/Wafer-Map-Defect-Classification-with-CNN-WM-811k-Case-Study-/blob/main/output.md) ‚Üí Key visual outputs (graphs, heatmaps, sample wafer maps)
  
##  Key Features

Built with TensorFlow/Keras in Python (experimented on Kaggle).

Implemented two experimental pipelines:

Standard Train/Validation split

K-Fold Cross Validation for robustness

Applied class balancing strategies (weighted loss, smoothing) to address dataset imbalance.

Achieved ~85% validation accuracy with strong generalization performance.

##  Key Highlights

- **Dataset**: WM-811k (semiconductor wafer map defect dataset)  
- **Approach**: Convolutional Neural Network (CNN) implemented in Keras/TensorFlow  
- **Pipelines**:  
  - Hold-out validation (train/test split)  
  - 5-Fold Cross Validation for robustness  
- **Techniques Used**:  
  - Class balancing with smoothed weights  
  - Data augmentation for generalization  
  - Early stopping to prevent overfitting  
- **Performance**:  
  - ~85% accuracy across folds  
  - Strong classification on majority classes  
  - Improved stability on minority defect classes  
- **Evaluation Tools**: Accuracy/Loss curves, confusion matrices, and classification reports  

## üöÄ How to Run / Usage

## ‚ö†Ô∏è Full implementation is not shared due to dataset and IP sensitivity.
Instead, the workflow is summarized below:

Data Preparation

Extract wafer maps and resize to a consistent shape (e.g., 64√ó64).

Normalize pixel intensities.

Encode defect categories as integer labels.

Model Architecture

CNN with stacked Conv2D ‚Üí BatchNorm ‚Üí Pooling layers.

Dense layers with dropout for generalization.

Softmax output for multi-class classification.

# (Pseudocode)
model = Sequential([
    Conv2D(...), BatchNormalization(), MaxPooling2D(...),
    Conv2D(...), BatchNormalization(), GlobalAveragePooling2D(),
    Dense(..., activation="relu"), Dropout(0.5),
    Dense(num_classes, activation="softmax")
])

## Training Strategy

Baseline: Train/Validation split with data augmentation.

Robust: Stratified K-Fold Cross Validation.

Optimizer: Adam (tuned LR).

Loss: Categorical cross-entropy with class weights to handle imbalance.

EarlyStopping + ModelCheckpoint for best model retention.

Evaluation

Monitor training/validation accuracy & loss.

Generate classification report & confusion matrix.

Compare fold results for stability and generalization.

##  Results & Insights
Training Curves

Training accuracy steadily improves, with validation accuracy stabilizing around 85%.

Loss convergence shows no severe overfitting, demonstrating good model stability.

Confusion Matrix

Strong performance on major classes such as Edge-Ring, Edge-Loc, and Center.

Minor classes like Random, Scratch, and Near-Full show higher misclassification due to class imbalance.

Future work: Data augmentation and rebalancing techniques may further improve rare class recognition.

##  Tech Stack

Languages: Python

Frameworks: TensorFlow, Keras

Libraries: NumPy, Pandas, Scikit-learn, Matplotlib, Seaborn

Environment: Kaggle GPU runtime

##  Recommendations

Data Augmentation: Improve representation of rare defect types.

Advanced Architectures: Experiment with ResNet/EfficientNet for feature robustness.

Deployment Potential: This pipeline could be extended into a real-time wafer inspection system in an industrial setting.

## üìå Disclaimer

This project is a case study for learning and demonstration purposes only.

The dataset originates from the publicly available WM-811k dataset.

Full code is not released due to industrial sensitivity and potential IP considerations.




---

## ‚ö†Ô∏è Note
The **full dataset and source code are not shared** due to confidentiality and intellectual property considerations.  
This repository serves as a **portfolio case study** to demonstrate applied ML methodology in semiconductor manufacturing.

---

##  Industry 4.0 Relevance
-  AI-driven **quality control**  
-  **Big Data + Deep Learning** for manufacturing analytics  
-  **Automation** of defect classification  
-  Supports **yield improvement** and **predictive maintenance**

---

 Author: Chew Chia Yik  
üîó Connect with me on [LinkedIn](https://www.linkedin.com/in/chew-chia-yik/)  
